# -*- coding: utf-8 -*-
"""IDS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AJwasfc6PAYywk--P-USIrWMIGwsH-Ro
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

column_names = [
    "duration","protocol_type","service","flag","src_bytes","dst_bytes",
    "land","wrong_fragment","urgent","hot","num_failed_logins",
    "logged_in","num_compromised","root_shell","su_attempted",
    "num_root","num_file_creations","num_shells","num_access_files",
    "num_outbound_cmds","is_host_login","is_guest_login","count",
    "srv_count","serror_rate","srv_serror_rate","rerror_rate",
    "srv_rerror_rate","same_srv_rate","diff_srv_rate",
    "srv_diff_host_rate","dst_host_count","dst_host_srv_count",
    "dst_host_same_srv_rate","dst_host_diff_srv_rate",
    "dst_host_same_src_port_rate","dst_host_srv_diff_host_rate",
    "dst_host_serror_rate","dst_host_srv_serror_rate",
    "dst_host_rerror_rate","dst_host_srv_rerror_rate",
    "label","difficulty"
]

train_df = pd.read_csv("KDDTrain+.txt", names=column_names)
test_df = pd.read_csv("KDDTest+.txt", names=column_names)

print("Train shape:", train_df.shape)
print("Test shape:", test_df.shape)

train_df.drop("difficulty", axis=1, inplace=True)
test_df.drop("difficulty", axis=1, inplace=True)

train_df["label"] = train_df["label"].apply(lambda x: "normal" if x == "normal" else "attack")
test_df["label"] = test_df["label"].apply(lambda x: "normal" if x == "normal" else "attack")

categorical_cols = ["protocol_type", "service", "flag"]

combined = pd.concat([train_df, test_df])

combined = pd.get_dummies(combined, columns=categorical_cols)

train_df = combined[:len(train_df)]
test_df = combined[len(train_df):]

print(combined)

combined.isnull().sum()

important_features = [
    "src_bytes",
    "dst_bytes",
    "count",
    "srv_count",
    "serror_rate",
    "srv_serror_rate",
    "same_srv_rate",
    "dst_host_count",
    "dst_host_srv_count",
    "dst_host_serror_rate",
    "dst_host_srv_serror_rate",
    "rerror_rate",
    "srv_rerror_rate"
]

X_train = train_df[important_features]
y_train = train_df["label"]

X_test = test_df[important_features]
y_test = test_df["label"]

le = LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.transform(y_test)

print("Classes:", le.classes_)  # normal=1, attack=0 (or reverse)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=300,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=2,
    class_weight="balanced",
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, classification_report

y_pred = model.predict(X_test)

print("Classification Report:\n")
print(classification_report(y_test, y_pred))

print("Confusion Matrix:\n")
print(confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=["Normal", "Attack"]
)

disp.plot(cmap="Blues")
plt.title("Confusion Matrix – IDS")
plt.show()

print(classification_report(y_test, y_pred, target_names=["Normal", "Attack"]))

from sklearn.metrics import roc_curve, auc

y_probs = model.predict_proba(X_test)[:,1]

fpr, tpr, thresholds = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0,1], [0,1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve – IDS")
plt.legend()
plt.show()

import joblib

joblib.dump(model, "ids_rf_important_features.pkl")
joblib.dump(important_features, "important_features.pkl")

